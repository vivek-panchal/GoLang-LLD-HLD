Why Load Balancing is Needed?
-> High Availability: Ensure system uptime even under high traffic or server failures.
-> traffic distribution : Spreads requests evenly across servers to prevent overload.
-> Prevent overload: Avoids overburdening a single server, ensuring optimal performance.
-> Improves Performance: Reduces latency and enhances user experience by directing traffic to the most responsive servers.
-> Handles Failures: Automatically reroutes traffic from failed servers to healthy ones, maintaining service continuity.
-> Supports Scalability: Facilitates horizontal scaling by adding or removing servers based on demand.

Types of Load Balancers:
1. Based on Layers:
   - Layer 4 (Transport Layer): Operates at the TCP/UDP level, distributing request based on network level data. 
   - Layer 7 (Application Layer): Operates at the HTTP/HTTPS level, making decisions based on request content (e.g., URL, headers).

2. Based on Deployment:
   - Hardware Load Balancers: Dedicated physical devices designed for load balancing tasks. Examples include F5, Citrix ADC.
   - Software Load Balancers: Applications or services that perform load balancing on standard hardware. Examples include HAProxy, Nginx, and Traefik.
   - Cloud-based Load Balancers: Load balancing services provided by cloud providers, offering scalability and flexibility. Examples include AWS ELB, Google Cloud Load Balancing, Azure Load Balancer.

Load Balancing Strategies:
 Static Load Balancing:
	1. Round Robin: Distributes requests sequentially across all servers in a circular order.
	2. Least Connections: Directs traffic to the server with the fewest active connections, optimizing resource use.
	3. IP Hash: Routes requests based on the client's IP address, ensuring consistent server access for users.
	4. Weighted Round Robin: Similar to Round Robin but assigns more requests to higher-capacity servers.
	5. Random: Distributes requests randomly across all servers, providing a simple load balancing mechanism.
Dynamic Load Balancing:
	1. Least Response Time: Directs traffic to the server with the lowest response time, optimizing user experience.
	2. Adaptive Load Balancing: Continuously monitors server load and adjusts traffic distribution in real-time.
	3. Resource-Based Balancing: Considers server resource usage (CPU, memory) to make routing decisions.
	4. Session Awareness: Maintains user session information to route requests from the same user to the same server.
	5. Geo-Location Based: Routes requests based on the user's geographic location, reducing latency.

Choosing the Right Load Balancer:
	1. Layer 4 vs Layer 7: Use Layer 4 load balancers for TCP/UDP traffic where speed is critical, and Layer 7 load balancers for HTTP/HTTPS traffic where content-based routing is needed.
	2. Hardware vs Software vs Cloud: Choose based on budget, scalability needs, and existing infrastructure.
	3. Static vs Dynamic: Use static strategies for predictable traffic patterns and dynamic strategies for variable or high-traffic environments.
